{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[03032019-1] RT-TEST-BATCH100.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BingHung/AI/blob/master/%5B03032019_1%5D_RT_TEST_BATCH100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dYVaFLZgsnn4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os.path\n",
        "import sys\n",
        "import re\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import csv \n",
        "\n",
        "def load_graph(model_file):                                  #讀取已經訓練好的模型 是.pb檔\n",
        "  graph = tf.Graph()\n",
        "  graph_def = tf.GraphDef()\n",
        "\n",
        "  with open(model_file, \"rb\") as f:\n",
        "    graph_def.ParseFromString(f.read())\n",
        "  with graph.as_default():\n",
        "    tf.import_graph_def(graph_def)\n",
        "\n",
        "  return graph\n",
        "\n",
        "\n",
        "def read_tensor_from_image_file(file_name,                   #修改欲預測的圖片尺寸 變成299*299\n",
        "                                input_height=299,\n",
        "                                input_width=299,\n",
        "                                input_mean=0,\n",
        "                                input_std=255):\n",
        "\n",
        "  input_name = \"file_reader\"\n",
        "  output_name = \"normalized\"\n",
        "  file_reader = tf.read_file(file_name, input_name)\n",
        "  if file_name.endswith(\".png\"):\n",
        "    image_reader = tf.image.decode_png(\n",
        "        file_reader, channels=3, name=\"png_reader\")\n",
        "  elif file_name.endswith(\".gif\"):\n",
        "        image_reader = tf.squeeze(\n",
        "        tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n",
        "  elif file_name.endswith(\".bmp\"): \n",
        "    image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n",
        "  else:\n",
        "    image_reader = tf.image.decode_jpeg(\n",
        "        file_reader, channels=3, name=\"jpeg_reader\")\n",
        "  float_caster = tf.cast(image_reader, tf.float32)\n",
        "  dims_expander = tf.expand_dims(float_caster, 0)\n",
        "  resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
        "  normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
        "  with tf.Session() as sess:\n",
        "      a = sess.run(float_caster)\n",
        "      result = sess.run(normalized)\n",
        "  # sess = tf.Session()\n",
        "  \n",
        "  return result\n",
        "\n",
        "\n",
        "def load_labels(label_file):                               #讀取用來分類的label檔案\n",
        "\n",
        "  label = []\n",
        "  proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
        "  for l in proto_as_ascii_lines:\n",
        "    label.append(l.rstrip())\n",
        "\n",
        "  return label\n",
        "\n",
        "def func(listTemp, n):\n",
        "    for i in range(0, len(listTemp), n):\n",
        "        yield listTemp[i:i + n]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  file_name = \"tensorflow/examples/label_image/data/grace_hopper.jpg\"\n",
        "  model_file = \\\n",
        "    \"tensorflow/examples/label_image/data/inception_v3_2016_08_28_frozen.pb\"\n",
        "  label_file = \"tensorflow/examples/label_image/data/imagenet_slim_labels.txt\"\n",
        "  input_height = 299\n",
        "  input_width = 299\n",
        "  input_mean = 0\n",
        "  input_std = 255\n",
        "  input_layer = \"input\"\n",
        "  output_layer = \"InceptionV3/Predictions/Reshape_1\"\n",
        "\n",
        "  parser = argparse.ArgumentParser()                           #設定可以輸入的變數,例如選擇哪個模型 選擇要預測的圖片\n",
        "  parser.add_argument(\"--image\", help=\"image to be processed\")\n",
        "  parser.add_argument(\"--graph\", help=\"graph/model to be executed\")\n",
        "  parser.add_argument(\"--labels\", help=\"name of file containing labels\")\n",
        "  parser.add_argument(\"--input_height\", type=int, help=\"input height\")\n",
        "  parser.add_argument(\"--input_width\", type=int, help=\"input width\")\n",
        "  parser.add_argument(\"--input_mean\", type=int, help=\"input mean\")\n",
        "  parser.add_argument(\"--input_std\", type=int, help=\"input std\")\n",
        "  parser.add_argument(\"--input_layer\", help=\"name of input layer\")\n",
        "  parser.add_argument(\"--output_layer\", help=\"name of output layer\")\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  if args.graph:\n",
        "    model_file = args.graph\n",
        "  if args.image:\n",
        "    file_name = args.image\n",
        "  if args.labels:\n",
        "    label_file = args.labels\n",
        "  if args.input_height:\n",
        "    input_height = args.input_height\n",
        "  if args.input_width:\n",
        "    input_width = args.input_width\n",
        "  if args.input_mean:\n",
        "    input_mean = args.input_mean\n",
        "  if args.input_std:\n",
        "    input_std = args.input_std\n",
        "  if args.input_layer:\n",
        "    input_layer = args.input_layer\n",
        "  if args.output_layer:\n",
        "    output_layer = args.output_layer\n",
        "\n",
        "  #========================================================\n",
        "  # MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1  # ~134M\n",
        "\n",
        "  image_dir = file_name # \"test_loop\"\n",
        "  files_list = []\n",
        "  file_glob = os.path.join(image_dir, '*.jpg')\n",
        "  files_list.extend(tf.gfile.Glob(file_glob)) #展開所有檔案並存入 files_list\n",
        "\n",
        "  x = []\n",
        "  for file_list in func(files_list, 100):\n",
        "   # print('====\\n'*5,len(file_list),'====\\n'*5)\n",
        "        \n",
        "    iCount =0\n",
        "    ans = pd.DataFrame() #轉csv檔使用\n",
        "    ans2=[]\n",
        "    ans3=[]\n",
        "    ans4=[]\n",
        "    ok_labels =[\"ok\", \"OK\", \"Ok\", \"normal\", \"NORMAL\", \"Normal\"]\n",
        "    \n",
        "    graph = load_graph(model_file)\n",
        "    test_images = list()\n",
        "    \n",
        "    for file_name in file_list: \n",
        "      t = read_tensor_from_image_file(\n",
        "        file_name,\n",
        "        input_height=input_height,\n",
        "        input_width=input_width,\n",
        "        input_mean=input_mean,\n",
        "        input_std=input_std)\n",
        "      test_images.append(t)\n",
        "\n",
        "    test_images = np.array(test_images)\n",
        "    test_images = np.reshape(test_images, (-1, 299, 299, 3))\n",
        "    \n",
        "    input_name = \"import/\" + input_layer\n",
        "    output_name = \"import/\" + output_layer\n",
        "    \n",
        "    input_operation = graph.get_operation_by_name(input_name)\n",
        "    output_operation = graph.get_operation_by_name(output_name)\n",
        "\n",
        "    with tf.Session(graph=graph) as sess:                       #sess.run 開始進行預測的運算 \n",
        "      results = sess.run(output_operation.outputs[0], {\n",
        "        input_operation.outputs[0]: test_images\n",
        "      })\n",
        "\n",
        "    # results = np.array(results)\n",
        "    # print(results)\n",
        "    # print(results.shape)\n",
        "    for i,c in enumerate(file_list):\n",
        "      a = []\n",
        "      a.append(c)\n",
        "      if results[i][1]>results[i][0]:\n",
        "        a.append('ok')\n",
        "        a.append(results[i][1])\n",
        "        a.append(results[i][0])\n",
        "      else:\n",
        "        a.append('ng')\n",
        "        a.append(results[i][1])\n",
        "        a.append(results[i][0])\n",
        "      x.append(a)\n",
        "   # print(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  with open('C:/tmp/fhi_predict1.csv','w', newline='') as scorecsv:\n",
        "    score = csv.writer(scorecsv)\n",
        "    score.writerow(['id','class','ok','ng'])\n",
        "    for row in x:\n",
        "    #print(row)\n",
        "      score.writerow(row)\n",
        "  scorecsv.close()\n",
        "\n",
        "    # results = np.squeeze(results)\n",
        "\n",
        "\n",
        "    # # top_k = results.argsort()[-5:][::-1]\n",
        "    # labels = load_labels(label_file)\n",
        "    \n",
        "    # path_name = image_dir #\"test\"\n",
        "    # bottleneck_string2=\"\"    \n",
        "    # max_x=\"\"\n",
        "    # max_y=0\n",
        "    # b=1\n",
        "    # for i in top_k:                                            #把預測圖片資料夾裡每張圖片預測的結果存起來\n",
        "    #   # print(\"--b=\",labels[i], results[i]) \n",
        "    #   b +=1\n",
        "    #   if results[i]>max_y:\n",
        "    #         max_x=labels[i]\n",
        "    #         max_y=results[i]  \n",
        "    #   bottleneck_string2 = bottleneck_string2+\"\\t\"+labels[i]+\": \"+str(results[i])+\" \"  \n",
        "    #   #print(labels[i], results[i])\n",
        "    \n",
        "    # ans2.append(file_name)\n",
        "    # ans3.append(max_x)\n",
        "    # ans4.append(bottleneck_string2)\n",
        "    # iCount +=1\n",
        "    # print('=============main for_loop end=============')\n",
        "      \n",
        "    # #轉出csv檔案\n",
        "    # ans[\"Id\"]= ans2\n",
        "    # ans[\"Class\"]= ans3\n",
        "    # ans[\"Class2\"]= ans4\n",
        "    # ans.to_csv(\"C:/tmp/fhi_predict.csv\", index=False)\n",
        "    # print(\"C:\\\\tmp\\fhi_predict.csv \",str(iCount)+\" files.\")\n",
        "    # print('%s: ' % datetime.now())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}